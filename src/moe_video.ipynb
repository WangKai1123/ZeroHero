{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基础版理解MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基础版 \n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicExpert(nn.Module):\n",
    "    def __init__(self,feature_in,feature_out):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(feature_in,feature_out)\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128])\n"
     ]
    }
   ],
   "source": [
    "class BasicMOE(nn.Module):\n",
    "    def __init__(self, feature_in, feature_out,num_experts):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(feature_in,num_experts)\n",
    "        # output shape (batch_size, num_export)\n",
    "        self.experts = nn.ModuleList(\n",
    "            BasicExpert(\n",
    "                feature_in,feature_out\n",
    "                )for _ in range(num_experts)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        # x shape is(batch, feature_in)\n",
    "        expert_weights = self.gate(x)\n",
    "        expert_out_list = [\n",
    "            expert(x) for expert in self.experts\n",
    "        ] # 每一个expert输出一个（batch, feature_out)\n",
    "        \n",
    "        expert_outputs = [\n",
    "            expert_out.unsqueeze(1)\n",
    "            for expert_out in expert_out_list\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        # expert out 是(b,1,feature_out)\n",
    "        expert_output = torch.concat(\n",
    "            expert_outputs,\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        # expert out 是(b,1,feature_out)\n",
    "        expert_output = torch.concat(\n",
    "            expert_outputs,\n",
    "            dim=1,\n",
    "        )\n",
    "        # expert_output shape (b, num_experts,feature_out)\n",
    "\n",
    "        # expert_weights\n",
    "        expert_weights = F.softmax(expert_weights, dim=1)\n",
    "        # expert_weights shape(b, num_experts)\n",
    "\n",
    "        # (b ,1, num_experts)\n",
    "        expert_weights  =expert_weights.unsqueeze(1)\n",
    "        # (batch,1,feature_out)  希望的输出\n",
    "        output = expert_weights @ expert_output\n",
    "        return output.squeeze(1)\n",
    "\n",
    "def test_basic_moe():\n",
    "    x = torch.rand(4,512)\n",
    "    basic_moe = BasicMOE(512,128,4)\n",
    "    output = basic_moe(x)\n",
    "    print(output.shape)\n",
    "\n",
    "\n",
    "\n",
    "test_basic_moe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparseMoE  和上述基本的比起来，MOE选择topK个专家，然后对这个TopK的专家输出进行加权求和，并且把输入样本变成了大模型中真实的输入Shape,(batch,seq_len,hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "class MOEConfig:\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim,\n",
    "            expert_number,\n",
    "            top_k,\n",
    "            shared_experts_number=2\n",
    "            ):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.expert_number = expert_number\n",
    "        self.top_k = top_k\n",
    "        self.shared_experts_number = shared_experts_number\n",
    "\n",
    "\n",
    "class MOERouter(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(config.hidden_dim, config.expert_number)\n",
    "\n",
    "        # 但是后面只会选 top_k 个专家\n",
    "\n",
    "        self.expert_number = config.expert_number\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        # 假设 Expert number 是8，top_k 是2\n",
    "        router_logits = self.gate(x) # (batch * seq_len, expert_number)\n",
    "\n",
    "        # 计算每一个专家的概率\n",
    "        router_probs = F.softmax(router_logits, dim=1,dtype=torch.float)\n",
    "\n",
    "\n",
    "        # topK是可以进行反向传播的  ，下面要求出topk专家的权重和索引\n",
    "        #这段代码的主要目的是为了实现一种机制，可以动态地为每个输入（或者每个时间步长的输入）\n",
    "        # 选择最合适的几位专家，并获取这些专家的相关权重和索引，以便进一步处理或计算。\n",
    "        router_weights, selected_expoerts_indices = torch.topk(\n",
    "            router_probs,\n",
    "            self.top_k,\n",
    "            dim=-1\n",
    "        )  # router_weights, selected_experts_indices\n",
    "            #shape 都是(batch* seq_len, top_k)\n",
    "\n",
    "        # 重新做一次归一化\n",
    "        router_weights = router_weights / router_weights.sum(\n",
    "            dim=-1,keepdim=True\n",
    "        )\n",
    "\n",
    "        router_weights = router_weights.to(x.dtype)\n",
    "\n",
    "        expert_mask = F.one_hot(\n",
    "            selected_expoerts_indices,\n",
    "            num_classes=self.expert_number,\n",
    "        ) # (batch * seq_len, top_k, expert_number)\n",
    "\n",
    "        expert_mask = expert_mask.permute(2,1,0)\n",
    "        # (expert_number, top_k, batch* seq_len)\n",
    "\n",
    "        return router_logits, router_weights, selected_expoerts_indices,expert_mask\n",
    "        # router_logits (batch* seq_len, expert_number)\n",
    "        # router_weights (batch* seq_len, top_k)\n",
    "        # router_logits (batch* seq_len, top_k)\n",
    "        # router_logits (expert_number,top_k, batch * seq_len)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SparseMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.top_k = config.top_k\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.expert_number = config.expert_number\n",
    "\n",
    "        # 初始化专家\n",
    "        self.experts = nn.ModuleList(\n",
    "            BasicExpert(\n",
    "                config.hidden_dim,\n",
    "                config.hidden_dim,\n",
    "            ) for _ in range(config.expert_number)\n",
    "        )\n",
    "        self.router = MOERouter(self.config)\n",
    "    def forward(self,x):\n",
    "        # x shape (batch, seq_len, hidden_dim)\n",
    "\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "\n",
    "        # token 维度计算, x reshape (batch * seq_len, hidden_dim)\n",
    "        hidden_states = x.view(-1, hidden_dim)\n",
    "        #做相关的专家计算\n",
    "        router_logits, router_weights, selected_experts_indices,expert_mask = self.router(\n",
    "            hidden_states\n",
    "        )\n",
    "\n",
    "        # expert_mask shape (expert_number, top_k, batch* seq_len)\n",
    "        # 最终肯定是 (batch*seq_len, hidden_dim)\n",
    "        final_hidden_states = torch.zeros(\n",
    "            (batch_size*seq_len, hidden_dim),\n",
    "             dtype=hidden_states.dtype,\n",
    "             device=hidden_states.device\n",
    "            \n",
    "        )\n",
    "\n",
    "        # 遍历每一个专家\n",
    "        # 把选中这个专家的token的hidden_states 加到 final_hidden_states 中\n",
    "        # export = 0 可能是有100个token被选中 \n",
    "        # token 的总数是 batch * seq_len\n",
    "\n",
    "        for expert_idx in range(self.expert_number):\n",
    "            expert_layer = self.experts[expert_idx]\n",
    "\n",
    "            current_expert_mask = expert_mask[expert_idx]\n",
    "\n",
    "            router_weights_idx, top_x = torch.where(current_expert_mask)\n",
    "            # idx 是0 or 1  假设TopK 是2\n",
    "            # 表示这个toekn是作为当前专家的 top1 还是 top2\n",
    "\n",
    "            # top_x 是token 在 batch * seq_len 中的位置索引、\n",
    "            # 例如对于 batch_size=2, seq_len=4 的输入\n",
    "            # top_X 的直范围是0-7, 表示在展评后的8个token中的位置\n",
    "            # 都是一个一维的直\n",
    "            # idx 肯定是用来选 Weight\n",
    "            # top_x 用来选 hidden_states\n",
    "\n",
    "            # hidden_states # shape 是 (1, batch * seq_len, hidden_dim)\n",
    "            current_state = hidden_states.unsqueeze(\n",
    "                0\n",
    "            )[:,top_x,:].reshape(-1,hidden_dim)\n",
    "\n",
    "            current_state = expert_layer(current_state)\n",
    "            # current_state shape (selected_token_number, hidden_dim)\n",
    "            # 100个 token 选中了\n",
    "            # router_weights Shape 是 (batch * seq_len, top_k)\n",
    "            current_token_router_weight = router_weights[top_x,router_weights_idx]\n",
    "            # 最终的 current_token_router_weight shape \n",
    "            # 就变成了 （selected_token_number)\n",
    "            current_token_router_weight = current_token_router_weight.unsqueeze(-1)\n",
    "            # 最终的 current_token_router_weight share\n",
    "            # 就变成了 （selected_token_number,1)\n",
    "\n",
    "            # (selected_token_number, hidden_dim)\n",
    "            # (seletted_token_number,1) 这里有广播\n",
    "\n",
    "            current_hidden_states = current_state * current_token_router_weight\n",
    "\n",
    "\n",
    "            #把当前专家的输出加到 final_hidden_states 中\n",
    "            final_hidden_states.index_add_(\n",
    "                0,\n",
    "                top_x,\n",
    "                current_hidden_states.to(hidden_states.dtype)\n",
    "            )\n",
    "\n",
    "        # 把 final_hidden_states 还原到原来的shape\n",
    "        final_hidden_states = final_hidden_states.reshape(batch_size,seq_len,hidden_dim)\n",
    "\n",
    "        return final_hidden_states, router_logits # shape 是 (b*s, expert_number)\n",
    "\n",
    "def test_token_level_moe():\n",
    "    x = torch.rand(2, 4, 16)\n",
    "    config = MOEConfig(16, 2, 2)\n",
    "    token_level_moe = SparseMOE(config)\n",
    "    out = token_level_moe(x)\n",
    "    print(out[0].shape, out[1].shape)\n",
    "\n",
    "test_token_level_moe()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
